## Hi there ðŸ‘‹ I'm Yanqing Liu

Iâ€™m a first-year Ph.D. student at UC Santa Cruz, advised by Prof. Cihang Xie.  
My research lies at the intersection of **multimodal learning**, **vision-language pretraining**, and **vision foundation models**.

I'm particularly interested in building **vision-centric large models** that serve as general-purpose backbones for downstream tasks.  
I believe vision encoders should not only understand images, but also **interface naturally with language**, enabling broader reasoning and interaction across modalities.

### ðŸ”¬ Currently exploring:
- **Representation learning** for visual and multimodal understanding  
- Learning from **synthetic or weakly-labeled data** to improve scalability
- Open and reproducible vision backbones for multimodal research  

I'm also a contributor to open-source projects like [OpenVision](https://github.com/UCSC-VLAA/OpenVision), and I care about making powerful vision models **accessible and extensible** to the research community.

ðŸ“„ Check out my [personal homepage](https://yanqing0327.github.io/Yanqing.github.io/) for papers and updates!

---
